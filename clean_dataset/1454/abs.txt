Magnetic Resonance Imaging (MRI) of the brain has been used to investigate a wide range of neurological disorders, but data acquisition can be expensive, time-consuming, and inconvenient. Multi-site studies present a valuable opportunity to advance research by pooling data in order to increase sensitivity and statistical power. However images derived from MRI are susceptible to both obvious and non-obvious differences between sites which can introduce bias and subject variance, and so reduce statistical power. To rectify these differences, we propose a data driven approach using a deep learning architecture known as generative adversarial networks (GANs) . GANs learn to estimate two distributions, and can then be used to transform examples from one distribution into the other distribution. Here we transform TN-weighted brain images collected from two different sites into MR images from the same site. We evaluate whether our model can reduce site-specific differences without loss of information related to gender (male or female) or clinical diagnosis (schizophrenia or healthy) . When trained appropriately, our model is able to normalise imaging sets to a common scanner set with less information loss compared to current approaches. An important advantage is our method can be treated as a `black box' that does not require any knowledge of the sources of bias but only needs at least two distinct imaging sets.