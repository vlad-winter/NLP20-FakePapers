Lung cancer screening with low dose computed tomography (CT) was shown to reduce lung cancer mortality by _inline_eq_ (_cite_) . Yet, human error remains a significant problem to detect abnormalities. For instance, Missing a tumor (recognition error) and misdiagnosing (decision making error) are called perceptual errors (_cite_) . It's reported that _inline_eq_ of lung nodules are typically missed during the screening process (_cite_) . Over-diagnosis is another significant bias leading to unnecessary treatment which can cause harm and unnecessary medical expenses. To alleviate some of these errors, Computer Aided Detection/Diagnosis (CAD) systems have been developed (_cite_) . CADs are often known as second opinion tools and they help to reduce false negative findings (i.e., missing tumors by radiologists) . CADs also have serious limitations such as a large number of false positive findings and high execution times. Radiologists are expected to eliminate false positive findings generated by the CAD systems, which makes majority of CADs infeasible in routine practice. Vision scientists have focused on exploring human errors in screening for more than three decades (_cite_) . One way to explore these perceptual errors is to use eye-tracking technology. It provides information about image interpretation by modeling perceptual and cognitive processes of radiologists. In this paper, we introduce a paradigm-shift system that uses eye-tracking technology as a collaborative tool between radiologists and CAD systems. The rationale behind this idea comes from the fact that radiologists are good at eliminating false positives, which CADs often fail to achieve at a human level performance. On the other hand, CADs capture missing tumors better than the human observer. Because of this complementary properties, we call the proposed technology collaborative CAD (C-CAD) . Briefly, we develop an accurate and efficient deep learning algorithm that accepts input from an eye-tracking device, and presents the results to radiologists for their diagnostic evaluations. We hypothesize that combining the strength of radiologists and CAD systems will improve the screening/diagnosis performance. To test this hypothesis, we have conduct a lung cancer diagnosis experiment (with low dose CT scans) based on eye-tracking data recorded from multiple radiologists. We also show the applicability of our framework to multi-parametric MRI to conduct prostate cancer screening. We choose lung and prostate cancers due to their high rate of mortality and growth in N, thus confirming their clinical importance~ (_cite_) . To the best of our knowledge, the proposed study is the first approach that combines eye-tracking, graph sparsification, and multi-task image analysis in a single framework to make a CAD system. Most relevant studies as compared to individual steps of our algorithms are summarized in the following. Since we focus on two clinical screening examinations in this study (lung and prostate cancers), related studies are confined to only these two topics. Nevertheless, the method presented here can be generalized to other radiology screening examinations. Benefits of Screening: According to the American Cancer Society, lung and prostate cancers are the leading causes of death and also the fastest growing cancers in N (_cite_) . Medical imaging helps early detection of cancers, but in a recent lung cancer screening clinical trial, it was found that approximately _inline_eq_ of lung nodules were missed during the screening process by radiologists (_cite_) . Previous studies have shown that early diagnosis of cancers may have a greater impact on the population~ (_cite_) . However, many open questions remain in screening examinations. For instance, definition of at-risk population affects the patient's inclusion in the study. Timing and intervals of screening are adjusted by clinical trials, but there is no optimal method yet to justify these selections. Nevertheless, even in these suboptimal conditions, exciting research is ongoing in this field, thanks to more advanced CT scanners and development of computerized image analysis methods. CAD systems have shown to be useful in reducing false negative (missed tumor) cases, but the main issue with all CAD systems is the presence of a high false positive rate~ (_cite_) . For instance, when an automated lung nodule detection method was used in a study by ~ _cite_, N \% of the missed lung cancers were marked by the computer. Despite this catch, the false-positive rate was very high: N false positive findings per scan. Review of CAD systems in the deep learning era: In recent years, deep learning based algorithms revolutionized many fields including medical image analysis applications. In conventional CAD systems (i.e., prior to the deep learning era), hand-crafted feature design/extraction followed by a feature selection and classification scheme were the main steps. However, with the success of deep learning, this strategy has moved from feature engineering to feature learning . In very recent frameworks, Convolutional Neural Networks (CNN) have been used for feature extraction and off-the-shelf classification methods in most CAD systems~ (_cite_) . In this line of research, for instance, Hua et al. proposed using a Deep Belief Network and a CNN for lung nodule classification~ (_cite_) while Kumar et al. used deep features extracted from an autoencoder to classify nodules into malignant and benign~ (_cite_) . Deep learning based lung cancer detection has also been used as part of a screening strategy~ (_cite_) . In our previous works, we have developed various deep learning networks for lung cancer diagnosis~ (_cite_) . In those works, we have first incorporated shape information of lung nodules to improve diagnostic accuracy~ (_cite_) . In another approach, we investigated Gaussian Process algorithms along with CNN to incorporate radiographical interpretations of nodule appearances to improve diagnostic decisions~ (_cite_) . Later, we improved our network (called TumorNET) by converting the CNN into a multi-task deep learning strategy~ (_cite_) . A multi-task ND network for joint segmentation and false positive reduction of lung nodules in a semi-supervised manner was proposed in~ (_cite_) . Meanwhile, many studies in the recent literature focused on false positive reduction in lung nodule detection. Some utilized multiple CNNs for multi-view lung nodule analysis~ (_cite_), while some used ND CNNs for a more efficient analysis~ (_cite_) . Furthermore, a multi-scale analysis of lung nodules using multiple ND CNNs was proposed by~ (_cite_) . The literature pertaining to lung nodule detection and characterization via CNN is vast. A brief overview of some network architectures related to lung cancer diagnosis can be found in~ (_cite_) . Specific to prostate cancer detection from radiology scans, recent works investigated the application of CNNs using multi-parametric MRI~ (_cite_) and a semi-supervised approach for biopsy-guided cancer detection using a deep CNN (_cite_) . Deep learning has also been used extensively as a feature learning tool for various applications such as MRI based prostate segmentation (_cite_) . It is beyond the scope of this study to enlist all of the relevant papers in deep learning-based CAD systems in lung and prostate cancers. Herein, we devise a new approach for a CAD design, where deep learning is the part of a collaborative learning strategy. Our proposed framework is generic and its components can be replaced with newer networks, in the future, if desirable. Review of Visual Search Studies in Radiology: A key aspect of biological vision studies is to understand perceptual and/or cognitive errors and how radiologists search radiology scans for finding abnormalities. These studies extensively benefit from different eye-tracking technologies~ (_cite_) . Comparison of the visual search patterns of radiologists, and inferring local and global information from those patterns have accelerated the research in this field and led to a better understanding of the differences between expert and novice readers/radiologists, and general strategies for visual search in radiology scans. Some of these studies date back to the Ns. In spite of decades of work, available methods in the literature fail to provide: In particular, the interaction between radiologists and computers (either simple PACS or CAD systems) remain untouched except by a few seminal image analysis studies~ (_cite_) . Challenges: Realistic radiology experience with eye-tracking is not achieved yet, mainly because of technical complexities. Eye-tracking systems record data in ND and having a ND system needs an exact synchronization. Furthermore, one of the main challenges of quantitative modeling and comparison of gaze data stems from the difficulty of representing, analyzing, and interpreting dense eye-tracking data. This is not only technically challenging, but also computationally demanding~ (_cite_) . The closest study addressing these problems was conducted by (_cite_) who proposed the famous scanning and drilling paper analyzing gaze patterns at the global level. While scanners examine one slice of a radiology scan, more explicitly before moving to the next one, drillers keep going forward and backward in slices, moving through a ND stack of the scan. However, quantitative analysis of search patterns at the global and local level has never been addressed before . We believe that such mapping will be extremely useful since it can serve as a natural interface between radiologists and CAD systems in that details of the gaze patterns will be used to guide a CAD system when it is necessary. In other words, it is not possible to benefit from human visual search in CAD systems when search patterns are represented only at the global level. This forms the major challenge of the problem depicted in (N) . What we propose? In this study, we address these challenges by (N) developing an eye-tracking interface that provides a real radiology reading room experience and (N) performing an attention based clustering and sparsification of dense eye-tracking data for building a C-CAD. Our proposed algorithm preserves topological properties of the gaze data while reducing its size significantly. This allows us to quantitatively compare global search patterns of radiologists, extract radiologists' regions of interest (ROI) based on their level of attention during the screening process (local), and to combine this information with image content to do different image analysis tasks for each ROI. Radiologistâ€™s gaze data is represented as a graph and sparsified using the proposed attention based algorithm. Finally, a ND Deep Multi-Task CNN is presented to perform a joint process of false positive removal (FP removal) and segmentation for each ROI. An overview of the proposed framework (C-CAD) is illustrated in Fig.~ _ref_ for a lung cancer diagnosis example. Details of each module in the proposed framework are explained in the following sections. Our work is built upon our previous effort~ (_cite_), wherein we first thresholded the eye-tracking data by its time component to define potential attentional regions. Then, these regions (ROIs) were processed with computer vision based saliency models to remove some of the false positive regions from considerations. Final ROIs were used for image analysis, particularly for segmenting lung pathologies using attention. A ND random walk algorithm~ (_cite_) was utilized to segment those ROIs by combining visual saliency and visual attention information as seeds of the random walk algorithm. The average dice similarity of _inline_eq_ was achieved. In the current study, we significantly improve our design into a new level with multiple novel contributions. We believe that our work has significant broader impacts in radiology and imaging sciences and introduces several technical innovations as summarized below: Rest of the paper is organized as follows: In Section N, we describe the proposed hardware and software integration, details of data acquisition parameters, the proposed data representation technique with sparsification, and multi-task learning based deep learning algorithm for tumor diagnosis. In Section N, we report validation of the sparsification experiments followed by a lung cancer diagnosis experiment with the C-CAD. In Section N, we introduce the potential of the proposed C-CAD system to handle multi-parametric images and multi-screen based eye-tracking and image analysis in general. We conclude the paper with a discussion and summary in Section N.