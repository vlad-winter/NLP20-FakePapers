In this paper, we propose to use deep N-dimensional convolutional networks (ND CNNs) in order to address the challenge of modelling spectro-temporal dynamics for speech emotion recognition (SER) . Compared to a hybrid of Convolutional Neural Network and Long-Short-Term-Memory (CNN-LSTM), our proposed ND CNNs simultaneously extract short-term and long-term spectral features with a moderate number of parameters. We evaluated our proposed and other state-of-the-art methods in a speaker-independent manner using aggregated corpora that give a large and diverse set of speakers. We found that N) shallow temporal and moderately deep spectral kernels of a homogeneous architecture are optimal for the task; and N) our ND CNNs are more effective for spectro-temporal feature learning compared to other methods. Finally, we visualised the feature space obtained with our proposed method using t-distributed stochastic neighbour embedding (T-SNE) and could observe distinct clusters of emotions.